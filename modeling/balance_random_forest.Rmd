---
title: "balance_rf"
author: "Alex MacCalman"
date: "8/19/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```
We will build a multiclass random forest classifier to predict the type of volcano based on other volcano characteristics.  
Read in the data.  
```{r, cache=TRUE}

volcano <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-12/volcano.csv')
eruptions <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-12/eruptions.csv')
events <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-12/events.csv')
tree_rings <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-12/tree_rings.csv')
sulfur <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-12/sulfur.csv')
```
## Explore the data  
```{r}
# let's look at the volcano types
volcano %>% 
        count(primary_volcano_type, sort = TRUE)

# we will only classify a subset of these 26 types using case_when function. 
volcano_df <- volcano %>% 
        transmute(volcano_type = case_when(str_detect(primary_volcano_type, "Stratovolcano") ~ "Stratovolcano", str_detect(primary_volcano_type, "Shield") ~ "Shield", TRUE ~ "Other"),
                  volcano_number, latitude, longitude, elevation, tectonic_settings, major_rock_1) %>%
        mutate_if(is.character, factor)
        
```
Let's make a map.  
```{r}
library(maps)
world <- map_data("world")

ggplot() +
        geom_map(data = world, map = world, aes(long, lat, map_id = region),
                 color = "white", fill = "grey50", alpha = 0.2) + 
        geom_point(data = volcano_df,
                   aes(longitude, latitude, color = volcano_type), alpha = 0.8)
```

## Build a model. 
This example doesn't hold off a test set because there is not enough data. The bootstraps functions slips 25 sets of training and analysis sets.  
```{r}
library(tidymodels)

volcano_boot <- bootstraps(volcano_df)

```
Now we will create a recipe to prepare our data.  
```{r}
#this package allows us to balance our categories using nearest neighbors.
library(themis)
volcano_rec <- recipe(volcano_type ~ ., data = volcano_df) %>% 
        update_role(volcano_number, new_role = "Id") %>% #we want to keep volcano_number in the dataset but it is not a predictor or an outcome. This function scopes it out. 
        step_other(tectonic_settings) %>% #this collapses the levels that are not used very much. 
        step_other(major_rock_1) %>% 
        step_dummy(tectonic_settings, major_rock_1) %>% 
        step_zv(all_predictors()) %>% #removes anything that has zero variance
        step_normalize(all_predictors()) %>% 
        step_smote(volcano_type) # generate new examples of minority class using nearest neighbors. Over samples so that it is balanced.

volcano_prep <- prep(volcano_rec) # actually performs the recipe
juice(volcano_prep) # this shows what the prep did.
juice(volcano_prep) %>% 
        count(volcano_type) # this shows that the categories are balanced.
```

Model specification.  
```{r}
rf_spec <- rand_forest(trees = 1000) %>% 
        set_mode("classification") %>% 
        set_engine("ranger")
#create a workflow - a way to hold together the recipe and model
volcano_wf <- workflow() %>%
        add_recipe(volcano_rec) %>% 
        add_model(rf_spec)
```
Now we will fit a model.  
```{r, cache = TRUE}
volcano_res <- fit_resamples(
        volcano_wf,
        resamples = volcano_boot,
        control = control_resamples(save_pred = TRUE, 
                                     verbose = TRUE) # we save the predictions to see which volcanos were predicted or not.
)
```

## Explore results  

```{r}
volcano_res %>% 
        collect_metrics() #default metrics
#collect predictions
volcano_res %>% 
        collect_predictions() %>% 
        conf_mat(volcano_type, .pred_class)

volcano_res %>% 
        collect_predictions() %>% 
        group_by(id) %>% #group by id ot look at each bootstrap sample result
        ppv(volcano_type, .pred_class) %>% #positive prediction values
        ggplot(aes(.estimate)) +
        geom_histogram(bins = 10)
```
Now we will use variable imporatance to understand our model.  To do this, we fit a new model with all the data. 
```{r}
library(vip)

rf_spec %>% 
        set_engine("ranger", importance = "permutation") %>% 
        fit(
                volcano_type ~ .,
                data = juice(volcano_prep) %>% 
                        select(-volcano_number) %>% 
                        janitor::clean_names()
        ) %>% 
        vip(geom = "point")
        
```
make a map.  
```{r}
volcano_prep <- volcano_res %>% 
        collect_predictions() %>% 
        mutate(correct = volcano_type == .pred_class) %>% 
        left_join(volcano_df %>% 
                          mutate(.row = row_number()))

#now make a map
library(hexbin)
ggplot() +
        geom_map(data = world, map = world, aes(long, lat, map_id = region),
                 color = "white", fill = "grey50", alpha = 0.2) + 
        stat_summary_hex(data = volcano_prep,
                        aes(longitude, latitude, z = as.integer(correct)),
                        fun = "mean",
                        alpha = 0.7, bins = 60) +
        scale_fill_gradient(high = "cyan3", labels = scales::percent) +
        labs(fill = "Percent classied correctly")
```

